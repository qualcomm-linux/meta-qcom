From a0cc8afb62542e10c63af2ee104531eb577f21d4 Mon Sep 17 00:00:00 2001
From: Rob Clark <rob.clark@oss.qualcomm.com>
Date: Thu, 12 Jun 2025 13:46:30 -0700
Subject: [PATCH 1/5] FIXES

Upstream-Status: Pending
---
 tensorflow/lite/delegates/gpu/cl/inference_context.cc         | 4 ++--
 .../lite/delegates/gpu/common/task/work_group_picking.cc      | 2 +-
 2 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/tensorflow/lite/delegates/gpu/cl/inference_context.cc b/tensorflow/lite/delegates/gpu/cl/inference_context.cc
index fa28a4c6944..a8ce62b08a4 100644
--- a/tensorflow/lite/delegates/gpu/cl/inference_context.cc
+++ b/tensorflow/lite/delegates/gpu/cl/inference_context.cc
@@ -180,7 +180,7 @@ absl::Status GetBufferAssignment(
       const size_t height = shape.h * DivideRoundUp(shape.c, 4);
       size_t width_pixel_alignment = gpu_info.opencl_info.image_pitch_alignment;
       if (gpu_info.IsAdreno() && width_pixel_alignment % bytes_per_pixel == 0) {
-        width_pixel_alignment /= bytes_per_pixel;
+//        width_pixel_alignment /= bytes_per_pixel;
       }
       const size_t width_aligned = AlignByN(width, width_pixel_alignment);
       buffer_size = width_aligned * bytes_per_pixel * height;
@@ -661,7 +661,7 @@ absl::Status InferenceContext::AllocateBufferBasedTensors(
             gpu_info.opencl_info.image_pitch_alignment;
         if (gpu_info.IsAdreno() &&
             width_pixel_alignment % bytes_per_pixel == 0) {
-          width_pixel_alignment /= bytes_per_pixel;
+//          width_pixel_alignment /= bytes_per_pixel;
         }
         RETURN_IF_ERROR(CreateTensorSharedImage2DBuffer(
             *context, shared_buffers_[buffer_index].GetMemoryPtr(), tensor_desc,
diff --git a/tensorflow/lite/delegates/gpu/common/task/work_group_picking.cc b/tensorflow/lite/delegates/gpu/common/task/work_group_picking.cc
index 0469891179e..a4946b37fcd 100644
--- a/tensorflow/lite/delegates/gpu/common/task/work_group_picking.cc
+++ b/tensorflow/lite/delegates/gpu/common/task/work_group_picking.cc
@@ -278,7 +278,7 @@ void GetPossibleWorkGroups(TuningType tuning_type, const GpuInfo& gpu_info,
   switch (tuning_type) {
     case TuningType::kFast:
       work_groups->push_back(
-          GetWorkGroup(grid, kernel_info.max_work_group_size));
+          GetWorkGroup(grid, std::min(kernel_info.max_work_group_size, gpu_info.GetMaxWorkGroupSizeForX())));
       return;
     case TuningType::kExhaustive: {
       GetWorkGroupsAlignedToGrid(gpu_info, kernel_info, grid, work_groups);
-- 
2.34.1

